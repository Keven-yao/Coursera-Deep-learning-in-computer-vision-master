{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Tracking and Action Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video Anaylsis:\n",
    "\n",
    "- detect insteresting objects in the video\n",
    "- identify thier properties (assumptions, estimations, position)\n",
    "- recognize people action and events\n",
    "\n",
    "    For this, one need to have situation awareness, and need semantic data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motion Analysis:\n",
    "- important feature in video recognition\n",
    "- image and video differ due to motion\n",
    "- use of motion can help us identify people's mood, gender, etc\n",
    "- vector field of 2D motion projections is called motion field\n",
    "- measure motion field to measure the recognition\n",
    "\n",
    "\n",
    "Optical flow is the flow of frames. \n",
    "- One of the key problem in Video Analysis\n",
    "- Optical flow, vector (u, v)\n",
    "- For each point (x, y) in first frame, we need to find (x + u, y + v) in the second frame\n",
    "\n",
    "    Evaluation: \n",
    "    - Angular Error = optical flow field (u0, v0) * ground flow field (u1, v1) [dot product]\n",
    "    - End Point Error: distance between optical flow and ground flow  \n",
    "    \n",
    "Best Optical Flow method is guided upscaling (STAR Optical Flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object Tracking: \n",
    "\n",
    "- locating a moving object multiple times in a video\n",
    "- output: sequence of the traces of the object\n",
    "- anything apart from position of the object in the first frame is not identified\n",
    "\n",
    "    Challenges: \n",
    "    - have to track whole N frames\n",
    "    - appearance of the object change over time\n",
    "    - other objects can appear similar to the given object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Annotatioon, \n",
    "\n",
    "- target object is segmented by semi automatic image segmentation method\n",
    "- fit a bounding box\n",
    "- mark attributes (position, motion, etc)\n",
    "\n",
    "    - Accuracy: average overlap\n",
    "    - Roboustness: number of times a tracker drifts the target\n",
    "        - all good models are of CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual Tracking Methods:\n",
    "\n",
    "1\\. Model Free Tracking (roboust to shape changes, sensitive to blur)\n",
    "\n",
    "Representing Objects:\n",
    "- as a model\n",
    "- as within keypoints\n",
    "- vector of appearances\n",
    "\n",
    "Template Matching with Normalized Cross Co-Relation\n",
    "\n",
    "2\\. Color based tracking (Iterative Object Tracking) - roboust to blur and sensitive to shape changes\n",
    "\n",
    "Stapble ( 1 + 2 ), one of the best models\n",
    "\n",
    "\n",
    "3\\. CNN\n",
    "- object vs ground classifier [Multi-Domain Visial Tracker]\n",
    "- apply to sample selected candidates\n",
    "- select region with highest score\n",
    "-----------------------------------------\n",
    "- generic video tracking [GOTURN]\n",
    "- take current image, and crop it two fit the object completely, making it two set of images\n",
    "- 2 images as input\n",
    "- output will be bounding box in the current frame (fast)\n",
    "\n",
    "MdNet is slow, and only required when high accuracy is the prime factor in the model\n",
    "\n",
    "\n",
    "If no GPU are used, then non-CNN models should be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
